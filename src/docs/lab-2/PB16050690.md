# 语法分析器实验报告

*PB16050690 莫志康*

## 实验目的
+ 实现pl/0的语法分析器
+ 在进行语法分析的过程中输出语法分析树
+ 实现一部分错误处理

## 小组合作情况
+ 首先确定了语法树的输出形式，利用栈的出栈、入栈操作实现对语法树的维护和输出，之后确定不同模块之间共通的代码部分，每个人分工一部分生产式的实现，汇总后进行code review，最后通过不同的测试样例对该语法分析器进行调试、修改

## 个人工作
+ 我负责条件语句、表达式、项、因子的产生式的处理

+ (1)语句的产生史处理比较复杂，因为其涉及到很多的递归，以及语句序列后的begin end后面的分号处理。每个产生式的处理都相似，将向前读的记号与FIRST集合进行匹配，从而进入到不同产生式的处理中。而在确定了所要展开成的产生式后，首先要进行对语法栈的维护，即压入相应的字符并打印该语法栈，这段代码是在每一个产生式的处理函数中通用的，不过要进行相应的压入字符串的修改。在进入相应的处理函数前，都要往前读一个记号，进入函数意味着按照该产生式展开。

~~~
/*functions for syntax analysis*/
void statement(PL0Lex * lex) {
	if (lex->last_token_type == TOKEN_IDENTIFIER) {
		popstack(syntax, temp);
		pushstack(syntax, "EXP");
		pushstack(syntax, "BECOMES");
		pushstack(syntax, "ident");
		printstack(syntax);
		popstack(syntax, temp);
		printstack(syntax);
		PL0Lex_get_token(lex);
		if (lex->last_token_type == TOKEN_BECOMES) {
			popstack(syntax, temp);
			printstack(syntax);
			PL0Lex_get_token(lex);
			if (lex->last_token_type == lex->last_token_type == TOKEN_IDENTIFIER || lex->last_token_type == TOKEN_NUMBER ||
				lex->last_token_type == TOKEN_MINUS || lex->last_token_type == TOKEN_LPAREN) expression(lex);
		}
		else if (lex->last_token_type == TOKEN_EQU) {  
			//error1 case; Found "=" when expecting ":="
			DealError(lex, 1);
			popstack(syntax, temp);
			printstack(syntax);
			PL0Lex_get_token(lex);
			if (lex->last_token_type == lex->last_token_type == TOKEN_IDENTIFIER || lex->last_token_type == TOKEN_NUMBER ||
				lex->last_token_type == TOKEN_MINUS || lex->last_token_type == TOKEN_LPAREN) expression(lex);
		}
		else if (lex->last_token_type == lex->last_token_type == TOKEN_IDENTIFIER || lex->last_token_type == TOKEN_NUMBER ||
			lex->last_token_type == TOKEN_MINUS || lex->last_token_type == TOKEN_LPAREN) { 
			//error 10 : statement missing an ident
			//printf("There should be a := after identifier\n");
			DealError(lex, 10);
			popstack(syntax, temp);
			printstack(syntax);
			PL0Lex_get_token(lex);
			 expression(lex);
		}
		else {
			DealError(lex, 0);//undefined error
		}
	}
	else if (lex->last_token_type == TOKEN_CALL) {
		popstack(syntax, temp);
		pushstack(syntax, "ident");
		pushstack(syntax, "CALL");
		printstack(syntax);
		popstack(syntax, temp);
		printstack(syntax);
		PL0Lex_get_token(lex);
		if (lex->last_token_type == TOKEN_IDENTIFIER) {
			popstack(syntax, temp);
			printstack(syntax);
			PL0Lex_get_token(lex);
		}
		else if (lex->last_token_type == TOKEN_SEMICOLON) { 
			//error case 9 : call statement missing an ident
			popstack(syntax, temp);
			printstack(syntax);
			DealError(lex, 9);
			
		}
	}
	else if (lex->last_token_type == TOKEN_BEGIN) {
		popstack(syntax, temp);
		pushstack(syntax, "END");
		pushstack(syntax, "STATEMENTLIST");
		pushstack(syntax, "BEGIN");
		printstack(syntax);
		popstack(syntax, temp);
		printstack(syntax);
		PL0Lex_get_token(lex);
		statementlist(lex);
		if (lex->last_token_type == TOKEN_END) {
			popstack(syntax, temp);
			printstack(syntax);
			PL0Lex_get_token(lex);
		}
	}
	else if (lex->last_token_type == TOKEN_IF) {
		popstack(syntax, temp);
		pushstack(syntax, "STATEMENT");
		pushstack(syntax, "THEN");
		pushstack(syntax, "CONDITION");
		pushstack(syntax, "IF");
		printstack(syntax);
		popstack(syntax, temp);
		printstack(syntax);
		PL0Lex_get_token(lex);
		if(lex->last_token_type == TOKEN_IDENTIFIER || lex->last_token_type == TOKEN_NUMBER ||
			lex->last_token_type == TOKEN_MINUS || lex->last_token_type == TOKEN_LPAREN || lex->last_token_type == TOKEN_ODD)condition(lex);
		if (lex->last_token_type == TOKEN_THEN) {
			popstack(syntax, temp);
			printstack(syntax);
			PL0Lex_get_token(lex);
		}
		if (lex->last_token_type == TOKEN_IDENTIFIER || lex->last_token_type == TOKEN_CALL || lex->last_token_type == TOKEN_BEGIN
			|| lex->last_token_type == TOKEN_IF || lex->last_token_type == TOKEN_WHILE) {
			if (strcmp((syntax->element[syntax->top]), "THEN") == 0) {   
				//error case 6: there must be THEN to follow the IF
				popstack(syntax, temp);
				printstack(syntax);
				DealError(lex, 6);
			}
			statement(lex);
		}
	}
	else if (lex->last_token_type == TOKEN_WHILE) {
		popstack(syntax, temp);
		pushstack(syntax, "STATEMENT");
		pushstack(syntax, "DO");
		pushstack(syntax, "CONDITION");
		pushstack(syntax, "WHILE");
		printstack(syntax);
		popstack(syntax, temp);
		printstack(syntax);
		PL0Lex_get_token(lex);
		if (lex->last_token_type == TOKEN_IDENTIFIER || lex->last_token_type == TOKEN_NUMBER ||
			lex->last_token_type == TOKEN_MINUS || lex->last_token_type == TOKEN_LPAREN || lex->last_token_type == TOKEN_ODD)condition(lex);
		if (lex->last_token_type == TOKEN_DO) {
			popstack(syntax, temp);
			printstack(syntax);
			PL0Lex_get_token(lex);
		}
		if (lex->last_token_type == TOKEN_IDENTIFIER || lex->last_token_type == TOKEN_CALL || lex->last_token_type == TOKEN_BEGIN
			|| lex->last_token_type == TOKEN_IF || lex->last_token_type == TOKEN_WHILE) {
			if (strcmp((syntax->element[syntax->top]), "DO") == 0) {   
				//error case 5: there must be DO to follow the WHILE
				popstack(syntax, temp);
				printstack(syntax);
				DealError (lex, 5);
			}
			statement(lex);
		}
	}
	else {
		printf("不应该进入statement analysis\n");
	}
	printf("analysis the statement\n");
}

~~~
+ (2)语句序列的处理涉及到递归，这里对下一个向前读的记号进行判断，若是分号则继续递归调用`void statement(lex)`进行分析

~~~
void statementlist(PL0Lex * lex) {
	popstack(syntax, temp);
	printstack(syntax);
	do {
		if (lex->last_token_type == TOKEN_SEMICOLON) {
			popstack(syntax, temp);
			printstack(syntax);
			PL0Lex_get_token(lex);
		}
		pushstack(syntax, "SEMICOLON");
		pushstack(syntax, "STATEMENT");
		printstack(syntax);
		if (lex->last_token_type == TOKEN_IDENTIFIER || lex->last_token_type == TOKEN_CALL || lex->last_token_type == TOKEN_BEGIN
			|| lex->last_token_type == TOKEN_IF || lex->last_token_type == TOKEN_WHILE) statement(lex);
		else {
			//printf("当前词法单元不在语句的first集合中\n");
			popstack(syntax, temp); popstack(syntax, temp);
			printstack(syntax);
		}
		
	} while (lex->last_token_type == TOKEN_SEMICOLON);
	printf("Finished list\n");
}

~~~
+ (3)表达式、项的产生式处理都比较相似，都是根据FOLLOW集合判断下一步是否得到期望的记号，若是则进入下一层分析，最后进入到因子产生式的分析中，而因子展开成终结符或者是继续递归进行expression的分析。

~~~

void expression(PL0Lex * lex) {
	popstack(syntax, temp);
	pushstack(syntax, "TERM");
	printstack(syntax);
	//PL0Lex_get_token(lex);
	term(lex);
	while (lex->last_token_type == TOKEN_MINUS || lex->last_token_type == TOKEN_PLUS) {
		pushstack(syntax, "TERM");
		if (lex->last_token_type == TOKEN_MINUS) pushstack(syntax, "MINUS");
		if (lex->last_token_type == TOKEN_PLUS) pushstack(syntax, "PLUS");
		printstack(syntax);
		popstack(syntax, temp);
		printstack(syntax);
		PL0Lex_get_token(lex);
		term(lex);
	}
	printf("analysis the expression\n");
}

~~~

~~~

void factor(PL0Lex * lex) {
	if (lex->last_token_type == TOKEN_IDENTIFIER) {
		popstack(syntax, temp);
		pushstack(syntax, "ident");
		printstack(syntax);
		popstack(syntax, temp);
		printstack(syntax);
		PL0Lex_get_token(lex);
	}
	else if (lex->last_token_type == TOKEN_NUMBER) {
		popstack(syntax, temp);
		pushstack(syntax, "NUMBER");
		printstack(syntax);
		popstack(syntax, temp);
		printstack(syntax);
		PL0Lex_get_token(lex);
	}
	else if (lex->last_token_type == TOKEN_MINUS) {
		popstack(syntax, temp);
		pushstack(syntax, "EXP");
		pushstack(syntax, "MINUS");
		printstack(syntax);
		popstack(syntax, temp);
		printstack(syntax);
		PL0Lex_get_token(lex);
		if (lex->last_token_type == TOKEN_IDENTIFIER || lex->last_token_type == TOKEN_NUMBER ||
			lex->last_token_type == TOKEN_MINUS || lex->last_token_type == TOKEN_LPAREN) {
			expression(lex);
		}
	}
	else if (lex->last_token_type == TOKEN_LPAREN) {
		popstack(syntax, temp);
		pushstack(syntax, ")");
		pushstack(syntax, "EXP");
		pushstack(syntax, "(");
		printstack(syntax);
		popstack(syntax, temp);
		printstack(syntax);
		PL0Lex_get_token(lex);
		if (lex->last_token_type == TOKEN_IDENTIFIER || lex->last_token_type == TOKEN_NUMBER ||
			lex->last_token_type == TOKEN_MINUS || lex->last_token_type == TOKEN_LPAREN) {
			expression(lex);
		}
		if (lex->last_token_type == TOKEN_RPAREN) {
			popstack(syntax, temp);
			printf("temp = %s  是右括号就对了\n", temp);
			printstack(syntax);
			PL0Lex_get_token(lex);
		}
		if (strcmp(syntax->element[syntax->top], ")") == 0) { 
			//error case 7 : missing a  )
			DealError(lex, 7);
			popstack(syntax, temp);
			printstack(syntax);
		}
		
	}
	printf("analysis the factor\n");
}

~~~

## 实验反思

+ (1)分工成不同的模块后要确定每个模块的接口，例如读取下一个字符统一在进入下一个分析函数前进行，进入函数后意味着已经确定了所要用的展开式。有一个模块就是因为多读了一次记号，导致后面的语法分析不能正常进行。

+ (2)对递归函数的功能和进入递归前栈的状态自习分析，每次进入下一个分析函数前都要对栈进行维护，而当发生错误时也要对栈有正确的操作。在实现简略的错误分析时就经常犯这个错误，例如压入栈的字符不正确，对源文件的当前位置分析不清，导致跳出错误后没有能接着正确地进行语法分析。

+ (3)我们的这个语法分析器的语法分析过程在大多数时候没有利用语法栈进行分析，而是通过一层层的逻辑保证过程正确，这样的确能够快速地实现简单的语法分析，但是更复杂一些的错误分析就没有能实现。

+ (4)错误分析应该可以通过对每个产生式构造一个FOLLOW集合和一个接受出错集合来对每一个向前读的记号的可能进行对应的操作，由于时间关系没有能完善，之后仍会不断进行完善，当前这个版本的分析器只实现了一些简单的错误，如漏了一些保留字和保留字错误，具体的实现在DeallError()函数中。